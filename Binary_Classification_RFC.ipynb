{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary_Classification_RFC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Binary Clasification of Text data. \n",
        "The following project can be used for applications where input data is a string of large text data and output is a binary classification of data. An example of the use of the below project could be sentiment classification ofcomments, hate speech detection, etc.\n",
        "\n",
        "Algorithm used : Random Forest Classifier\n",
        "\n",
        "Data used for this project: \n",
        "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
        "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
        "  title     = {Learning Word Vectors for Sentiment Analysis},\n",
        "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
        "  month     = {June},\n",
        "  year      = {2011},\n",
        "  address   = {Portland, Oregon, USA},\n",
        "  publisher = {Association for Computational Linguistics},\n",
        "  pages     = {142--150},\n",
        "  url       = {http://www.aclweb.org/anthology/P11-1015}\n",
        "}\n",
        "\n",
        "\n",
        "Reference: https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34\n"
      ],
      "metadata": {
        "id": "BfP9VsyKMxyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import  necessary packages"
      ],
      "metadata": {
        "id": "CVVqeatUM8An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njMAUPwxQnAd",
        "outputId": "73ac5807-5137-4794-9ad2-7807ffe2484a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading And Preprocessing Data"
      ],
      "metadata": {
        "id": "lqS5IHVPSeVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(500)\n",
        "Corpus = pd.read_csv(\"IMDB Dataset.csv\",encoding='latin-1',engine='python',error_bad_lines=False)\n",
        "\n",
        "# 1. : Drop empty rows.\n",
        "Corpus['review'].dropna(inplace=True)\n",
        "# 2. : All text is made lower case. Different case words treated as separate words. If this s relevant for the data, you can skip the below step.\n",
        "Corpus['review'] = [entry.lower() for entry in Corpus['review']]\n",
        "# 3. : Tokenization(Breaking sentences to words)\n",
        "Corpus['review']= [word_tokenize(entry) for entry in Corpus['review']]\n",
        "# 4. : Remove Stop words using WordNetLemmatizer\n",
        "tag_map = defaultdict(lambda : wn.NOUN)\n",
        "tag_map['J'] = wn.ADJ\n",
        "tag_map['V'] = wn.VERB\n",
        "tag_map['R'] = wn.ADV\n",
        "for index,entry in enumerate(Corpus['review']):\n",
        "    Final_words = []\n",
        "    word_Lemmatized = WordNetLemmatizer()\n",
        "    for word, tag in pos_tag(entry):\n",
        "        if word not in stopwords.words('english') and word.isalpha():\n",
        "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
        "            Final_words.append(word_Final)\n",
        "    Corpus.loc[index,'text_final'] = str(Final_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmYqTudhV3JW",
        "outputId": "0ea7f6a6-4c94-4c7b-b7e4-dfeb1973e6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Skipping line 34068: unexpected end of data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide Text in Train(75%) and Test(25%) sets"
      ],
      "metadata": {
        "id": "EHuW1frsW-oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['sentiment'],test_size=0.3)"
      ],
      "metadata": {
        "id": "6GeC6crUXJCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Label to 0 and 1"
      ],
      "metadata": {
        "id": "NYrt5mPAXeTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)"
      ],
      "metadata": {
        "id": "YWOcQ5FYXi_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Text to Vectors(Vectorization)"
      ],
      "metadata": {
        "id": "liMPpd6CX6Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tfidf_vect = TfidfVectorizer(max_features=10000)\n",
        "Tfidf_vect.fit(Corpus['text_final'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
      ],
      "metadata": {
        "id": "U6T8XHrJYJWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train The Model. Here we will use 4 different Algorithms and compare the same"
      ],
      "metadata": {
        "id": "TiL_HdVHYdMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Train - Random Forest Classifier"
      ],
      "metadata": {
        "id": "ZIMkkNPIYmpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the model we are using\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "#Tried with estimators 50, 100, 150. After 100 estimators, the improvement was negligible(<2%)\n",
        "rf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "\n",
        "# Train the model on training data\n",
        "rf.fit(Train_X_Tfidf,Train_Y);"
      ],
      "metadata": {
        "id": "8ouHflsUtIez"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Test - Random Forest Classifier"
      ],
      "metadata": {
        "id": "TyknnrekZCQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the labels on  test set\n",
        "predictions_rf = rf.predict(Test_X_Tfidf)\n",
        "print(\"RF Accuracy Score -> \",accuracy_score(predictions_rf, Test_Y)*100)\n",
        "print(\"RF Precision Score -> \",precision_score(predictions_rf, Test_Y)*100)\n",
        "print(\"RF Recall Score -> \",recall_score(predictions_rf, Test_Y)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVBuX24iZM_T",
        "outputId": "22ba9577-3666-46df-c996-e5d98800882c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Accuracy Score ->  84.45205479452055\n",
            "RF Precision Score ->  83.96300669027941\n",
            "RF Recall Score ->  84.64590359055742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To predict value for a particular Review or sentence use following code:"
      ],
      "metadata": {
        "id": "rC6nf5p6hXN7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF6OD5GYOu-1"
      },
      "source": [
        "print(Encoder.inverse_transform(Test_Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiOnxXTINVv8",
        "outputId": "af8a4218-ba05-40d7-a601-7a78a608b3b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Encoder.inverse_transform(SVM.predict(Tfidf_vect.transform([\"This is a good good day.\"])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['N'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}